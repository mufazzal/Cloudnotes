S3 and CloudFront(CDN) :-
  When you use the apt 'GET <s3-object-url>' to download any S3 resource, it usues the typiccal internet to load the file to client side.
  Now suppose you have bkt in usa and downloading the file in india, it will take hell of the time. 
  To minimize this time the solution is use CloudFront for the bucket.
  
  Cloud front in itself a large aws service, this serve fast delivery of many S3 servoce like S3, EC2, Rout53 etc
  For now we will see How S3 and CloudFront (CFT) interact.
  
    How to set it up:-
      in a nutshell you set CFT distribution with below info
        - Buccket
        - prefix
      and you get
        - A CFT url for this distribution.
    Now you should use the CFT url to invole CFT.
    
    mechanism:-
      User do GET <cft url for bucket> and query for an object
      The request reaches to nearest EL.
      It check if EL has the cache of that object.
      if yes
        then provide it from cache.
      if no
        then EL us the aws backbone netrwork to get that object 
        the retrived object saved in cache.
        and response returned with that object to user.
      
      - EL only keep the cache of the file/object that are at least being quried at once, if it never being quried then it will not be at that EL. 
  
  
  First lets make a bkt in farthest region possible 'mufa-cdf-enbled-bucket'.
  also say there is many folder in this bucket and you just wants a specific folder ('myDistItems') to be over CFT.
  so create couple of folder including 'myDistItems'. also create 'mufWebsite' and 'mufPriv'
  There is no single setting you have to do here for CFT, it all will be done on AWS > CFT page itself.  
  
  lets create the distribution-
  Steps:-
    Simply go to AWS > Cloud Front > Create > web
    Fill the form, lets see mos imp things to fill for S3:-
    
    Origin Domain Name: 
      Select from the existing value, this will be related to bkt that we have create ealier
      choose option 'mufa-cdf-enbled-bucket.s3.amazonaws.com'. 
      So for S3, this is simply a   <Bucket Name>.s3.amazonaws.com
    Origin Path: 
      This is will be the folder inside that bucket, all the content inside the chossed folder will be accessible via 
      this CFT-distribution. anything outside this folder will not be accessible via this 'CFT-distribution'
      lets type here 'myDistItems'
      
    The above two param plays the vital Role in mapping of Object and CFL paths.
    you have bkt as
      mufa-cdf-enbled-bucket
        fruits
          apple, oranges, mangos [hafua, badam]
        veg
          potato, ginger, onion [big, small] 

    Say you create two diffrent distribution by choosing those
      dist for fruits:-
        Origin Domain Name = mufa-cdf-enbled-bucket.s3.amazonaws.com
        Origin Path = fruits
        ...so..
        The generate CDN url =>  blablabla.cloudfront.net
        By this url you can access - 
            blablabla.cloudfront.net/apple
            blablabla.cloudfront.net/oranges
            blablabla.cloudfront.net/mangos/hafua
         but not
            blablabla.cloudfront.net/fruits/apple  --> That is because the fruots itself is a root folder
            blablabla.cloudfront.net/potato
            blablabla.cloudfront.net/ginger
            blablabla.cloudfront.net/onion/big
            
        
      dist for veg:-
        Origin Domain Name = mufa-cdf-enbled-bucket.s3.amazonaws.com
        Origin Path = veg
        ...so..
        The generate CDN url =>  claclacla.cloudfront.net
        By this url you can access - 
            claclacla.cloudfront.net/potato
            claclacla.cloudfront.net/ginger
            claclacla.cloudfront.net/onion/big
         but not
            claclacla.cloudfront.net/veg/potato
            claclacla.cloudfront.net/apple
            claclacla.cloudfront.net/oranges
            claclacla.cloudfront.net/mangos/hafua  
      
    Restrict Bucket Access: 
      YEs! if you wants to restrict the accessibilitry only and only via CDN, not via direct S3 url
      ?????????????????????????
      
    Origin ID: unique id of this origin, I do not know why they call it a IT. better call it description or alias
      Enter a description for the origin. This value lets you distinguish multiple origins in the same distribution from one another. 
      ??????????????????????????
      
    Origin Access Identity: 
      This is just like(but not same) as IAM user, which is created to access the bucket. 
      Here you can either new identity or use the existing one. [its list is at AWS > CFT > security > Origin Access Identity]
      
    Grant Read Permissions on Bucket: 
      The identity you chossed in option 'Origin Access Identity', must have permission to perform 'GetObject' api on bucket.
      so BP of that bucket to allow the GetObject operation over tye bkt 'mufa-cdf-enbled-bucket'.
      
      If above two option is saetup properly then you will be able to observe two thing after distribution deployed.
      1. at page  AWS > CFT > security > Origin Access Identity  you can see the new identity created with id 'uidOF_OriginAccessIdentity'.
      2. in BP of 'mufa-cdf-enbled-bucket' there is a statement added automatically-
      ...
          "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::cloudfront:user/CloudFront Origin Access Identity <uidOF_OriginAccessIdentity>"
            },
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::mufa-cdf-enbled-bucket/*"          
      ...
    
    Viewer Protocol Policy: 
      you can restric user either to use HTTP or to use HTTPS. Also you can configure to redirect any HTTP 
      to HTTPS. but such redirection will need a SSL certificate to. if you wants it then upload the SSL certifiate in option 'SSL Certificate' at tab 'Distribution Settings'
      Allowed HTTP Methods: which HTTP methodes are allowed, yoyu can allow 'GET, HEAD, OPTIONS, PUT, POST, PATCH, DELETE' methodes
      the confusion is, CFT mainly do viewing operatiojn so  How PUT, DELETE, POST works??????????????????????????
    
    Object Caching: 
        Maximum TTL: Once the objevt is cached at Edge-location, it may be possiblr that the file later changed at origin.
          To keepthe edgre location in synch it is must that the edge locations keep itself in synch to that origin.
          The max TTL time is the time that determine that how long the file will live at Edge-location.
          Once the TTL priode passed out the Edge-location communicate wuth origin and synch itself again.
          So any chages at origin will again be refected in edge-locations.
          
          So if you files in s3 buucket/folder is changing very rarly thaen keep the max TTL higher.
          but if it chages a lot then keep it small.expire.
  
   Restrict Viewer Access (Use Signed URLs or Signed Cookies): 
    yes! if you wants to use only personalized signed url to access the files.


What happen over CFT When
  1. You delete a file from S3 : 
        If you delete a file from S3 and this file may be alaredy over multiple edge location, then its deletion will not be immediatly
        reflected over all ELs, instead the CACHE of this file will remain over the all ELs till its TTL expire. and rhis cached file
        will be served to user.
        Once TTL expire the CFT make a sych request to origin (S3 bkt 'mufa-cdf-enbled-bucket' in our case)
        and look fot this object/file, once he is informed that its deleted then it will reflect it over all trhe ELs. 
        So deletion of file may not reflect immedietly but after the TTL expiration.

  2. Add new file in Bucket:-
       When uploaded upload it, at thattime the file will not be at ELs. becoz S3 upload do not care about CFT. 
       lets say the file key is 'graps' so when you do PUtObject operation on graps.txt, the fi;le will be uploaded obly on S3 bucket. thats it
       Now when any user make a request to CFT (not S3 bucket) for this object by calling 'blablabla.cloudfront.net/graps' 
       The file will be first cached from S3 to the nearest Edge location and then it will be served to the called.
       So in nutshell if new file is added the file be reflected as soon as somone call it via CFT url (no S3 url 'blablabla.s3.amazonaws.com/fruits/graps')
  
  3. When you cvhange the file:
        This work same as the delete one, it will be reflected after the TTL passed out.
        
  How S3-bucket and CFT synch :- 
      When i say su=ynch, it does not mns that all S3 object will be come into the CFT,
      CFT only keep the cache of the file/object that are at least being quried at once, if it never being quried then it will 
      neither it on ELs, nor synch it ever.
      Once the file is quried by any user then only its key is added on CFT and late those only keys are synched.
      When i say synch here, it means that synchronization between 
        CACHED file/object with the origin(Se). '
       not 
        file/object with the origin(Se). '
      


 Q: Does bkt must have all BPAF as off for CloudFront to work: 
    No, its value doesnt matter here.
   
 Q: Doest bucket must be public ?
    No, not neccesarily
 
 Q: Does OBject also has to have a public access
    No, not neccesarily
 

CFT url and Access:-
  Suppose a CFt is destribuction is created over a bucket that is protected by BP or IAL or ACL and user has to pass the Auth info with url.
  To achive this you can use CloudFront Signed URL.
  For this simply sign a CFT url as given in  https://medium.com/roam-and-wander/using-cloudfront-signed-urls-to-serve-private-s3-content-e7c63ee271db
  


Invalidate Cache on CFT:-
  As you know that after the TTL passes out the cache of file/object will get to be synched with origin, but you can also forcefully
  synch it with ortigin. use invalidate option for this.
  
  


 CloudFront VS Transfer-Acceleration : Cloud front is for CDN, its main goal is to make downloading of file asap. But TA is used for
                                        making upload asap.
 
 
       
     
